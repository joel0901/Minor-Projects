{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Blackcoffer_Assignment.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOnjFR13QSA7b41El/KoLRC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Importing necessary libraries\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import requests\n","import urllib.request \n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import cmudict\n","import string\n","\n","\n","# Mounting my google drive which will be used for the necessary files\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","\n","\n","# The directory containing the necessary files for this program\n","%cd \"drive/MyDrive/Blackcoffer\"\n","\n","\n","# Making dataframes of the data so that we can manipulate and update them\n","\n","# Input that was provided \n","excel_pd = pd.read_excel('Input.xlsx')\n","\n","# Publicly and universally accepted list of stop words which will help us find the stop words in any document\n","stop_pd = pd.read_csv('StopWords_Generic.txt')\n","\n","# Final excel sheet with the scores of each of the entries in the input excel\n","final_excel = pd.read_csv('Output Data Structure.xlsx')\n","\n","# This excel sheet contains all the words and states if a word is a negative or positive word and so on. \n","Words = pd.read_excel('LoughranMcDonald_MasterDictionary_2020.xlsx')\n","\n","\n","\n","# Creating two data frames for further use \n","\n","# Dataframe which will store the Positive words in a particular website\n","Positive = pd.DataFrame()\n","\n","# Dataframe which will store the Negative words in a particular website\n","Negative = pd.DataFrame()\n","\n","\n","\n","\n","# We now store all the positive words from dataframe 'Words' onto the newly made dataframe 'Positive'. If the column(in 'Words') corresponding to positive is non zero, then it is a positive word. \n","j = 0\n","for i in range (len(Words)):\n","  if Words['Positive'][i] > 0:\n","    Positive.loc[j,0] = Words['Word'][i]\n","    j = j + 1\n","\n","# We now store all the negative words from dataframe 'Words' onto the newly made dataframe 'Negative'. If the column(in 'Words') corresponding to negative is non zero, then it is a negative word. \n","j = 0\n","for i in range (len(Words)):\n","  if Words['Negative'][i] > 0:\n","    Negative.loc[j,0] = Words['Word'][i]\n","    j = j + 1\n","\n","\n","\n","\n","# We now calculate all the scores by running a for loop iterating over all the rows(and hence each of the websites)\n","\n","# We are creating a dictionary of all the words using this inbuilt library\n","syllables = dict(cmudict.entries())\n","\n","# Iterating over the entire input excel sheet\n","for i in range (len(excel_pd)):\n","\n","  # Corresponding to the row number (variable i), we select the website using get function\n","  html_text = requests.get('excel_pd.iloc[i][1]')\n","\n","  # We use BeautifulSoup to get the content of the document\n","  soup = BeautifulSoup(html_text.content)\n","\n","  # The condition for the text to be chosen is that it should be enclosed withing <p>....</p>. Hence this filter. Paras contain all the data enclosed within this filter\n","  paras = soup.find_all('p')\n","\n","  # Each of these variables are assigned a zero value whenever a new iteration(and hence, whenever a new document) is encounterted\n","  word_count, positive_score, negative_score, sentences, complex_count, overall_syllables = 0\n","\n","  # We now iterate over each paragraph of the document\n","  for para in paras:\n","\n","    # We now use the inbuilt python function to split the sentences to iterate over each individual word. \n","    for word in word_tokenize(para.text):\n","    \n","      # We capitalize each word because all the words in our dataframe are capital by default\n","      word = word.capitalize()\n","\n","      # There is a flaw in this logic, but I am counting a sentence whenever we encounter the characters '!', '.' and '?'. Also, they shouldnt be counted for any of the other scores, hence continuing with the for loop\n","      if (word == '.' or '!' or '?'):\n","        sentences = sentences + 1\n","        continue\n","\n","      # if the word is in the Stop dataframe (hence a stopword)\n","      if stop_pd.iloc[:,0].str.contains(word).any():\n","        continue\n","\n","      # Counting the words which have passed through\n","      word_count = word_count + 1\n","      \n","      # Checking to see if the word is in the positive daraframe(and hence a positive word )\n","      if Positive.iloc[:,0].str.contains(word).any():\n","        positive_score = positive_score + 1\n","\n","      # Checking to see if the word is in the negative daraframe(and hence a negative word )\n","      if Negative.iloc[:,0].str.contains(word).any():\n","        negative_score = negative_score + 1\n","\n","      # Counting the number of syllables using the dict we had made \n","      syllables_length = len( [ph for ph in syllables[word] if syllables.strip(string.letters)] )\n","      overall_syllables = overall_syllables + syllables_length\n","\n","      # If the syllable count is above 2, then we count it as a complex word\n","      if syllables_length > 2:\n","        complex_count = complex_count + 1                      \n","\n","    \n","  # We now fill the empty columns in the final_excel dataframe that we had created based on the scores we found and the formulas given\n","  final_excel.loc[i, 2] = positive_score\n","  final_excel.loc[i, 3] = negative_score\n","  final_excel.loc[i, 4] = (positive_score - negative_score) / ((positive_score + negative_score) + 0.0000001 )\n","  final_excel.loc[i, 5] = (positive_score + negative_score) / ((word_count) + 0.000001 )\n","  final_excel.loc[i, 7] = complex_count / word_count\n","  final_excel.loc[i, 8] = 0.4 * (final_excel.loc[i, 6]) + final_excel.loc[i, 7])\n","  final_excel.loc[i, 9], final_excel.loc[i, 6] = word_count / sentences\n","  final_excel.loc[i, 10] = complex_count\n","  final_excel.loc[i, 11] = word_count\n","  final_excel.loc[i, 12] = overall_syllables\n","  final_excel.loc[i, 14] = avg_word_length\n","\n","\n","\n","\n","# We now convert the final_excel dataframe to an excel sheet\n","final_excel.to_excel(\"Output Data Structure.xlsx\")"],"metadata":{"id":"wjFY5PcpKviG"},"execution_count":null,"outputs":[]}]}